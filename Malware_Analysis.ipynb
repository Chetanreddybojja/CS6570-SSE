{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bccf2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb796b7",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d67c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y): #returns correlation b/w inputs x & y\n",
    "    mean_x = sum(x)/float(len(x))\n",
    "    mean_y = sum(y)/float(len(y))\n",
    "    sub_x = [i-mean_x for i in x]\n",
    "    sub_y = [i-mean_y for i in y]\n",
    "    \n",
    "    std_deviation_x = sum([sub_x[i]**2.0 for i in range(len(sub_x))])\n",
    "    std_deviation_y = sum([sub_y[i]**2.0 for i in range(len(sub_y))])\n",
    "    \n",
    "    numerator = sum([sub_x[i]*sub_y[i] for i in range(len(sub_x))])\n",
    "    denominator = (std_deviation_x*std_deviation_y)**0.5\n",
    "    \n",
    "    try:\n",
    "        corr = numerator/denominator\n",
    "    except:\n",
    "        return 5     #non-0 for non-0 denominator\n",
    "    return corr\n",
    "\n",
    "#Top k features extraction\n",
    "def Extract(data, k):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i][:k]\n",
    "    return data\n",
    "\n",
    "# Separating into training & testinvg data\n",
    "def ExtractData(X_normal, X_malware, k):\n",
    "    X_normal = Extract(X_normal, k)\n",
    "    X_malware = Extract(X_malware, k)\n",
    "    \n",
    "    # 70% training and 30% test\n",
    "    y_normal = [0 for i in range(len(X_normal))]\n",
    "    y_malware = [1 for i in range(len(X_malware))]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normal, y_normal, test_size=0.3, random_state=1)\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_malware, y_malware, test_size=0.3, random_state=1)\n",
    "    X_train.extend(X_train2)\n",
    "    y_train.extend(y_train2)\n",
    "    X_test.extend(X_test2)\n",
    "    y_test.extend(y_test2)\n",
    "    \n",
    "    random_indices1 = list(range(len(X_train)))\n",
    "    random_indices2 = list(range(len(X_test)))\n",
    "    random.shuffle(random_indices1)\n",
    "    random.shuffle(random_indices2)\n",
    "    X_train_new = []\n",
    "    y_train_new = []\n",
    "    X_test_new = []\n",
    "    y_test_new = []\n",
    "\n",
    "    for idx in random_indices1:\n",
    "        X_train_new.append(X_train[idx])\n",
    "        y_train_new.append(y_train[idx])\n",
    "    for idx in random_indices2:\n",
    "        X_test_new.append(X_test[idx])\n",
    "        y_test_new.append(y_test[idx])\n",
    "\n",
    "    X_train = X_train_new\n",
    "    y_train = y_train_new\n",
    "    X_test = X_test_new\n",
    "    y_test = y_test_new\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Top k features from training & test data\n",
    "def ReduceData(X_train, y_train, X_test, y_test, k):\n",
    "    X_train = Extract(X_train, k)\n",
    "    X_test = Extract(X_test, k)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Model prediction accuracy computaton\n",
    "def ComputeAccuracy(y_pred, y_test):\n",
    "    match = (y_test == y_pred).sum()\n",
    "    accuracy = match/len(y_test)\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de056b5",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesNet\n",
    "#https://analyticsindiamag.com/a-guide-to-inferencing-with-bayesian-network-in-python/\n",
    "\n",
    "# Naive Bayes\n",
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "def NaiveBayes(X_train, y_train, X_test, y_test):\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    accuracy = ComputeAccuracy(y_pred, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# https://www.datacamp.com/tutorial/understanding-logistic-regression-python\n",
    "def Logistic(X_train, y_train, X_test, y_test):\n",
    "    logreg = LogisticRegression(max_iter=1000)\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    accuracy = ComputeAccuracy(y_pred, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# MultiPerceptron\n",
    "# https://scikit-learn.org/stable/modules/neural_networks_supervised.html#:~:text=Multi%2Dlayer%20Perceptron%20(MLP),number%20of%20dimensions%20for%20output.\n",
    "def MLP(X_train, y_train, X_test, y_test):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = ComputeAccuracy(y_pred, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# SGD : Stochastic Gradient Descent\n",
    "# https://scikit-learn.org/stable/modules/sgd.html\n",
    "def SGD(X_train, y_train, X_test, y_test):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = ComputeAccuracy(y_pred, y_test)\n",
    "    return accuracy\n",
    "'''\n",
    "Simple Logistic \n",
    "SMO \n",
    "JRIP\n",
    "OneR Classifier\n",
    "https://rasbt.github.io/mlxtend/user_guide/classifier/OneRClassifier/\n",
    "'''\n",
    "from mlxtend.classifier import OneRClassifier\n",
    "def OneR(X_train, y_train, X_test, y_test):\n",
    "    oner = OneRClassifier()\n",
    "    oner.fit(X_train, y_train)\n",
    "    oner.predict(X_train)\n",
    "    y_pred = oner.predict(X_test)\n",
    "    accuracy = ComputeAccuracy(y_pred, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Decision Tree based classifiers\n",
    "# https://www.datacamp.com/tutorial/decision-tree-classification-python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DecisionTree(X_train, y_train, X_test, y_test):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = ComputeAccuracy(y_pred, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply all the classifiers on the dataset\n",
    "def ApplyClassifiers(X_train, y_train, X_test, y_test):\n",
    "    accuracies = []\n",
    "    \n",
    "    # Naive Bayes Classifier\n",
    "    accuracy = NaiveBayes(X_train, y_train, X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Naive Bayes: {accuracy}\")\n",
    "    \n",
    "    # Logistic Regression\n",
    "    accuracy = Logistic(X_train, y_train, X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Logistic Regression: {accuracy}\")\n",
    "    \n",
    "    # Multilayer Perceptron\n",
    "    accuracy = MLP(X_train, y_train, X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Multilayer Perceptron: {accuracy}\")\n",
    "    \n",
    "    # Stochastic Gradient Descent (SGD)\n",
    "    accuracy = SGD(X_train, y_train, X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Stochastic Gradient Descent: {accuracy}\")\n",
    "    \n",
    "    # Decision Tree (J48)\n",
    "    accuracy = DecisionTree(X_train, y_train, X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Decision Tree: {accuracy}\")\n",
    "        \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ade698",
   "metadata": {},
   "source": [
    "## Read Data from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loded into pandas dataframe\n",
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractaction of benign and malware datapoints based on the binarylabel attribute from the data separately\n",
    "benign_df = data.loc[data['binarylabel'] == 0]\n",
    "benign_df_rows = benign_df.to_numpy().tolist()\n",
    "malware_df = data.loc[data['binarylabel'] == 1]\n",
    "malware_df_rows = malware_df.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c704d",
   "metadata": {},
   "source": [
    "## Re-order the data with the highest contributing (in terms of correlation) features first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f477b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_partition = []\n",
    "for i in range(len(benign_df_rows)):\n",
    "    c_partition.append(0)\n",
    "for i in range(len(malware_df_rows)):\n",
    "    c_partition.append(1)\n",
    "    \n",
    "required_feature = []\n",
    "\n",
    "# Computing Correlation for each feature\n",
    "for i in range(55):\n",
    "    temp = []\n",
    "    for j in range(len(benign_df_rows)):\n",
    "        temp.append(benign_df_rows[j][i])\n",
    "    for j in range(len(malware_df_rows)):\n",
    "        temp.append(malware_df_rows[j][i])\n",
    "    required_feature.append([abs(correlation(temp,c_partition)), i])\n",
    "\n",
    "# sort the correlation values\n",
    "required_feature.sort()\n",
    "\n",
    "# Normal and malware lists with decreasing ordered features\n",
    "# relevance (correlation)\n",
    "X_normal = []\n",
    "X_malware = []\n",
    "\n",
    "featurelist = []\n",
    "\n",
    "for i in range(32):\n",
    "    featurelist.append(required_feature[52-i][1])\n",
    "\n",
    "for i in range(len(benign_df_rows)):\n",
    "    X_normal.append([])\n",
    "    for j in range(32):\n",
    "        X_normal[i].append(benign_df_rows[i][featurelist[j]])\n",
    "\n",
    "for i in range(len(malware_df_rows)):\n",
    "    X_malware.append([])\n",
    "    for j in range(32):\n",
    "        X_malware[i].append(malware_df_rows[i][featurelist[j]])\n",
    "\n",
    "accuracies_global = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original, y_train_original, X_test_original, y_test_original = ExtractData(X_normal, X_malware, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using top 1 feature\n",
    "X_train, y_train, X_test, y_test = ReduceData(X_train_original, y_train_original, X_test_original, y_test_original, 1)\n",
    "accuracies = ApplyClassifiers(X_train, y_train, X_test, y_test)\n",
    "accuracies_global.append(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e16dbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using top 2 features\n",
    "#X_train, y_train, X_test, y_test = ExtractData(X_normal, X_malware, 2)\n",
    "X_train, y_train, X_test, y_test = ReduceData(X_train_original, y_train_original, X_test_original, y_test_original, 2)\n",
    "accuracies = ApplyClassifiers(X_train, y_train, X_test, y_test)\n",
    "accuracies_global.append(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9928b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using top 4 features\n",
    "X_train, y_train, X_test, y_test = ReduceData(X_train_original, y_train_original, X_test_original, y_test_original, 4)\n",
    "accuracies = ApplyClassifiers(X_train, y_train, X_test, y_test)\n",
    "accuracies_global.append(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10bdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using top 8 features\n",
    "X_train, y_train, X_test, y_test = ReduceData(X_train_original, y_train_original, X_test_original, y_test_original, 8)\n",
    "accuracies = ApplyClassifiers(X_train, y_train, X_test, y_test)\n",
    "accuracies_global.append(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using top 32 features\n",
    "X_train, y_train, X_test, y_test = X_train_original, y_train_original, X_test_original, y_test_original\n",
    "accuracies = ApplyClassifiers(X_train, y_train, X_test, y_test)\n",
    "accuracies_global.append(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfb1c7",
   "metadata": {},
   "source": [
    "## Creating a bar plot of accuracies for each classifier with different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34853b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.15\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# Set Bar height\n",
    "features_1 = accuracies_global[0]\n",
    "features_4 = accuracies_global[1]\n",
    "features_8 = accuracies_global[2]\n",
    "features_16 = accuracies_global[3]\n",
    "features_32 = accuracies_global[4]\n",
    " \n",
    "# Bar position on X axis\n",
    "br1 = np.arange(len(features_1))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    "br5 = [x + barWidth for x in br4]\n",
    " \n",
    "# Plotting\n",
    "plt.bar(br1, features_1, color ='r', width = barWidth, edgecolor ='grey', label ='1 Feature')\n",
    "plt.bar(br2, features_4, color ='g', width = barWidth, edgecolor ='grey', label ='2 Features')\n",
    "plt.bar(br3, features_8, color ='b', width = barWidth, edgecolor ='grey', label ='4 Features')\n",
    "plt.bar(br4, features_16, color ='c', width = barWidth,edgecolor ='grey', label ='8 Features')\n",
    "plt.bar(br5, features_32, color ='m', width = barWidth,edgecolor ='grey', label ='32 Features')\n",
    " \n",
    "# Xticks addition\n",
    "plt.xlabel('Classifiers', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r +2* barWidth for r in range(len(features_1))],\n",
    "        ['Naive Bayes', 'Logistic Regression', 'MultiPerceptron', 'SGD', 'Decision Tree'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454615d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5697b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e713d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93316ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a16b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b35d7e5b2f2f4d2cffea8d5d9f7c294a4aa949d94d8d5fb96b3df4625d954bec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
